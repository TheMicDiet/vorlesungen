\chapter{Powermanagement}

Zusammenfassung der Vorlesung "`Powermanagement"' aus dem Wintersemester 2016.\footnote{\url{https://os.itec.kit.edu/deutsch/3257_3262.php}}

\section{Einführung}
\begin{itemize}
	\item Energiedichte eines modernen \texttt{Core i7 Duo Mobile} vergleichbar mit einer Kochplatte. Energiedichte eines \texttt{Core i7 Hexa} sogar fünf Mal höher
	\item CPUs werden i.d.R. nicht gleichmäßig heiß, nutzungsabhängig entstehen verschieden heiße Teilbereiche
	\item \textbf{Motivation}
	\begin{itemize}
		\item Erhöhung der Lebensdauer der Akkus durch Effizienzverbesserung der Verbraucher: CPU-Scaling, Speicherenergiemanagement, I/O-Energiemanagement, Display-Energiemanagement, Ausschalten von Festplatten
		\item Task-spezifisches Powermanagement
		\item Einhalten eines Energieplans
		\item Vermeiden von Energiespitzen, da bestimmte Energiequellen ein definiertes Maximum liefern
		\item Bestimmte Temperatur darf nicht überschritten werden
		\item Energy-Accounting
	\end{itemize}
\end{itemize}



\section{CPU Powermanagement}

\subsection{Accounting}
\begin{itemize}
	\item \textbf{Methoden zur Feststellung des Energieverbauchs}
	\begin{itemize}
		\item Messung des Eingangsstroms an der CPU (Spannung ist bekannt): Hochfrequente, präzise Messung mit Messwiderstand notwendig; Auswertungsoverhead muss beachtet werden (Implementierung per Inline Assembler); CPU-Features (Turbo Boosts, Hyperthreading, etc.) sollten abgeschaltet werden; bei \textit{SoCs} nicht möglich
		\item Simulation der CPU: Extrem langsam (\(4000-10.000.000\)-mal langsamer als das Zielsystem); auf Schaltoperations- oder Instruktionslevel möglich; meist allerdings kein genaues Energiemodell des Zielprozessors vorhanden (lediglich \texttt{Reverse Engineertes})
		\item Auswerten der Energiezähler im Prozessor
		\begin{itemize}
			\item Ausmessen des Energieverbrauchs verschiedener Aktionen (Data/Instruction-Cache-Miss, Speicherzugriff, Cycle, Branch, etc.)
			\item Möglichkeit 1: Auslesen der Ereigniszähler im Prozessor; meist allerdings zu wenige vorhanden
			\item Möglichkeit 2: Mit dediziertem Co-Prozessor; wenig Overhead durch das Betriebssystem; minimale Seiteneffekte; in \textit{SoCs} integrierbar
			\item Vorteile: Wenig Overhead; hohe Auflösung; Prozess-granulare Messungen möglich
			\item Anwendungsbeispiel \texttt{P4}: Vergleichsweise genaue Messungen mit relativen Fehlern von \(< 10\%\) möglich
		\end{itemize}
	\end{itemize}
	\item Accounting muss alle beteiligten Komponenten erfassen: CPU-Zeit, Speicher, etc.
	\item Virtuelle Umgebungen: Accounting muss weitere Komponenten wie Zeit im Hyperviser (beispielsweise Treiberzugriffe) berücksichtigen
	\item Client-Server-Accounting: Ggf. mehrere Prozesse an Aufgabenerfüllung beteiligt
	\item \textbf{Resource Containers}
	\begin{itemize}
		\item Ziel: Ermitteln des "`Gesamtaufwands"' eines Services
		\item Accounting von CPU-Zeit (Userspace und Kernelmode) und Kernel-Objekte (Scokets, Netzwerkpuffer, etc.) nach Netzwerkverbindungen (Clients); Verwendung von Kontextinformationen des Schedulers
		\item Implementierung
		\begin{itemize}
			\item Via \texttt{File Descriptor} hierarchisch referenziert
			\item Attribute: Ressourcenverbrauch/-limitierung, Scheduling-Parameter, Zugriffsrechte, etc.
			\item Dynamische Bindung von Threads an Resource Containers
		\end{itemize}
	\end{itemize}
	\item \textbf{Energy Containers}
	\begin{itemize}
		\item Erweitern Resource Containers um ereignisgetriebenen Energiemessungen
		\item Stellen Informationen für Powermanagementrichtlinien zur Verfügung
		\item Beispiel: Limitierung des kurzfrisitigen, durchschnittlichen Energieverbauchs
	\end{itemize}
	\item Energy Inversion Problem: Das Energiebudget eines Clients wird aufgebraucht während dieser eine kritische Ressource hält (Client-Verbindung "`wird angehalten"' und die Ressource nicht freigegeben) \(\rightarrow\) Server ist blockiert bis die Energiebudgets aktualisiert werden
\end{itemize}


\subsection{Wärmemanagement}
\begin{itemize}
	\item \textbf{Vorteile, Chancen}
	\begin{itemize}
		\item Höhere Zuverlässigkeit der gekühlten Komponenten; Lüfterlautstärke/-geschwindigkeit kann reguliert werden; reduzierte Kosten
		\item Abwägung zwischen Systemleistung, Luftfluss und Bodenplatz
		\item Generelles Problem: Individuelle Lüftersteuerungen einzelner Server stören das Gesamtkühlkonzept im Rechenzentrum (beispielsweise durch Rückflüsse. Mögliche Gegenmaßnahme: Gangüberdachungen)
		\item Dynamische Verteilung/Reduzierung rechenintensiver Aufgaben
		\begin{itemize}
			\item Reduziert notwendige Kühlleistung
			\item Höhere Verfügbarkeit ohne Notwendigkeit einer redundanten Kühlung
		\end{itemize}
	\end{itemize}
	\item Vergleich \(P_{max}\) und \(P_{tdp}\): Wachsender Unterschied seit 1985, da Prozessoren verstärkt Wärmemanagement betreiben (beispielsweise können Komponenten auf der CPU abgeschaltet werden)
	\item Mehr Leistung durch Kühlung: Maximale Taktfrequenz stark von der Chip-Temperatur abhängig
	\item \textbf{Drosseln}
	\begin{itemize}
		\item Nicht sofort spürbar (Messung außerhalb der Funktionalen Einheiten, langsamer Zugriff am Temperatursensoren) \(\rightarrow\) frühzeitige Reaktion notwendig
		\item Strategien
		\begin{itemize}
			\item HLT-Cylces: Anhalten der CPU bis zum nächsten Interrupt (typischerweise \(1-10s\), spezielle Instruktion); schnelle Reaktions; bei vielen Interrupt keine präzise Steuerung möglich
			\item Dynamic Clock Modulation: Reduzierung der internen Taktfrequenz durch Überlagerung des normalen Takts durch zweiten, langsameren Takt
			\item Instruction decode throttling: Drosselung der weitergeleiteten Instruktion aus dem L1-Instruction-Cache in den Instruction-Buffer; schnelle Reaktionszeit; einfach in Hardware zu implementieren
			\item Dynamic Frequency and Voltage Scaling: \(P=C \cdot V_{cc}^2 \cdot F\) \(\rightarrow\) Reduzierung von Spannung oder Frequenz führt zu niedrigerer Energieaufnahme
		\end{itemize}
	\end{itemize}
\end{itemize}


\subsection{Dynamic Frquency and Voltage Scaling (DVS)}
\begin{itemize}
	\item \textbf{Beobachtungen/Messungen}
	\begin{itemize}
		\item Frequenzdrosselung bei Speicher-Zugriffe irrelevant, da ohnehin auf den Speicher gewartet werden muss
		\item Idealerweise sollte die Energieersparnis die Laufzeiteinbußen übertreffen
		\item Schnellerer Prozessortakt führt zu weniger Hauptspeicherenergiebedarf (Lokalisationsprinzip)
		\item Nicht immer ist bei Speicher die langsamste Frequenz die beste (abhängig vom Zugriffsmuster), ggf. braucht eine Task auf langsamerer Taktfrequenz mehr Leistung
	\end{itemize}
	\item \textbf{Richtlinien}
	\begin{description}
		\item{Policy \#1: PAST}
		\begin{itemize}
			\item Dynamisch, systemweit, intervalbasiert; Entscheidung basiert auf der vergangenen Auslastung
			\item Soll die Anzahl der Geschwindigkeitswechsel verringern
			\item Schlechte Leistung in vielen realistischen Scenarios (beispielsweise bursty Tasks)
		\end{itemize}
		\item{Policy \#2: Vertigo}
		\begin{itemize}
			\item Dynamisch, systemweit, intervalbasiert; Entscheidung basiert auf Event-/Task-Einstufung
			\item Aufbau des Algorithmus
			\begin{itemize}
				\item Unten: Algorithmische Bestimmung der zukünftigen Auslastung, basierend auf der vergangenen Auslastung. Pro Task werden Auslastung und Auslastungfenster festgelegt
				\item Mittig: Anwendungsabhängige Schicht zur Anmeldung von Leistungsbedarf (müssen die Anwendungen unterstützen)
				\item Oben: Automatische Ermittlung des Leistungsbedarfs interaktiver Anwendungen
			\end{itemize}
		\end{itemize}
		\item{Policy \#3: Process Cruise Control}
		\begin{itemize}
			\item Prinzip: Die Häufigkeit mit der Ereignisse auftreten hängen von einem spezifischen Leitungs- und Energieeffizienzprofil ab \(\rightarrow\) Ergeignis-basierte Charakterisierung: Sinkende Ereignisrate als Indikator für Durchsatzverlust
			\item Herausforderungen: Auswahl der geeigneten Ereignistypen; Finden des Zusammenhangs [Ereignisrate \(\leftrightarrow\) Energiebedarf]
			\item Limitierungen des Models: (Meist) zu geringe Anzahl an Ereigniszählern; Auswahl von Ereignissen mit Fokus auf Leistung (nicht auf Energy Profiling)
		\end{itemize}
	\end{description}
\end{itemize}



\section{Speicher Powermanagement} % TODO

\subsection{Charakteristik von DRAM}
\begin{itemize}
	\item Hintergrund: Leistungsfähigkeit vieler Komponenten (CPU, Grafikkarte, etc.) hängt von der Speicherperformance ab; Speicher macht bei mobilen Geräten \(>50\%\) des Energieverbrauchs aus
	\item Energieverbrauch bei DRAM: Refresh der Kondensatoren; Decoding; Datentransfer
	\item Vollgepufferte DIMMs: Zusätzlich \(4W\) Energieverbrauch
	\item Mobile DRAM
	\begin{itemize}
		\item Temperatur Compensated Self Refresh (TCSR): Refresh-Interval an Temperatur angepasst
		\item Partial Array Self Refresh (PASR): Nur Bereiche, die Daten enthalten, werden refresht
		\item Deep Power-Down (DPD): Array wird komplet abgeschalten; keine Datenspeicherung
	\end{itemize}
\end{itemize}


\subsection{DRAM Powermanagement}
\begin{itemize}
	\item Setup: Aufteilung des Speichers in Module; keine Speicherverschränkung\footnote{Aufeinander folgende Speicherworte werden zyklisch in aufeinander folgenden Speicherbänken abgespeichert. (Wikipedia)}; individuell angepasste Energielevel pro Modul
	\item Festlegen des Energieniveaus
	\begin{itemize}
		\item Wird automatisch vom Speichercontroller festgelegt: Zustandswechsel (beispielsweise von \texttt{Performancemodus} zu \texttt{Schlafzustand}), wenn innerhalb einer definierten Zeitspanne keine Anfragen kommen (\textit{Gaptime})
		\item Herausforderung: Gaptime gut wählen, da sonst viel Zeit/Energie für Zustandswechsel verbraucht wird. Abschätzung beispielsweise über Performancecounter, allerdings stark abhängig von Referenzmuster
		\item "`Intelligenter Speicherkontroller"'
		\begin{itemize}
			\item Kennt Zugriffsmuster/Dringlichkeiten/Prioritäten und verteilt die Daten entsprechend ( Lokalität ausnutzen)
			\item Kann zu Benachteiligung von Anfragen/Daten speichern. Gegenmaßnahme beispielsweise: Echtzeitrelevante Daten priorisieren. Idealerweise taggen von allen physischen Seiten (gap distribution, priorities, realtime, ...)
		\end{itemize}
	\end{itemize}
	\item Allgemeiner Trend: Anforderungen an Speichercontroller wachsen (Fehlererkennung/-maskierung, variable Geschwindigkeiten, etc.)
\end{itemize}


\subsection{Strategien für Page Allocation}
\begin{itemize}
	\item \textbf{Speicherallokationsstrategien (Software)}
	\begin{itemize}
		\item Ziel: Erhöhen der Gaptime der meisten Speichermodule
		\item Sequential First-Touch Allocation: Pages werden nach Möglichkeit in einem Modul allokiert, das schon Daten hält
		\item DLL Aggregation: Dediziertes Modul für gemeinsam genutzte Objekte (Shared Memory, Shared Libraries, Pipes, etc.)
	\end{itemize}
	\item \textbf{Speichermigrationsstrategien (Software)}
	\begin{itemize}
		\item Ziel: Erhöhen der Gaptime der meisten Speichermodule
		\item Idee: Erlaube (beschränktes) Verschieben von allokierten Pages; Zusammenfassen des aktiven Speichers in möglichst wenig Modulen
		\item Problem: Finden der Zugriffsfrequenzen
		\item Lösung: Protokollieren der Exceptions, die der Lastlevelcache wirft, wenn er voll ist \(\rightarrow\) ergibt welche Seiten wie oft referenziert worden sind. Mit extem hohem Aufwand verbunden 
		\item Shared Pages generelles Problem bei Migration
		\item Anwendung: Energiegewahres Garbage Collection, da diesem die Objektreferenzen bekannt sind. GC kann selbstständig Objekte verschieben
	\end{itemize}
	\item \textbf{Nachteile bei Page-Migrationen durch das Betriebssystem}
	\begin{itemize}
		\item MMU des Prozessors: TLBs benötigen viel Energie (zusätzlich noch mehr bei Miss durch Page-Table-Walk); Hardwarearchitektur der Caches nicht zum Speichern zusätzlicher Informationen (Referenzzähler, \#Einträge, etc.) geeignet
		\item Prozessor/DMA-Controller muss Transfers durchführen
		\item Komplexe Verwaltung muss vom Betriebssystem bewältigt werden können (dieses steuert die MMU)
	\end{itemize}
	\item \textbf{MMC: Trennung von Sicherung und Zuordnung}
	\begin{itemize}
		\item MMC-TLB: Speichert zusätzlich Anzahl der Lese-/Schreibzugriffe zu jeder Frame-Adresse; konfigurierbar (Anzahl Einträge, Assoziativität, etc.)
		\item Energiegewahre MMU mit dedizierter Speicherverschiebeeinheit
		\item Zusätzliche Funktionen
		\begin{itemize}
			\item Speicher-Controller kann Pages in persistentem Speicher backuppen
			\item Speicher-Controller kann virtuellen physikalischen Speicher "`anbieten"'
			\item Speicher-Controller unterstützt Hardware-Support für Speicherkomprimierung
		\end{itemize}
	\end{itemize}
\end{itemize}


\subsection{Speicherkomprimierung}
\begin{itemize}
	\item Hardware-unterstützte Komprimierung
	\begin{itemize}
		\item Dedizierte Hardware zum feingranularen (de-)komprimieren von Daten und Instruktionen
		\item Möglichkeiten von Energiesparen: Weniger Speicherzugriffe; weniger Anfragen auf dem Speicherbus; geringere Cache-/Speichergröße notwendig
	\end{itemize}
	\item Software-seitige Komprimierung
	\begin{itemize}
		\item Aufteilung in (un-) (Bsp.: Working Set)/komprimierte (nicht benutzte Pages) Speicherbereiche
		\item (De-)Komprimierungsgeschwindigkeit (asymmetrischer Algorithmus) entscheident
		\item Möglichkeiten zum Energiesparen: Geringere Speichergröße notwendig; die meisten Speichermodule können im Standby bleiben; Speicherkomprimierung kann DVS-optimal betrieben werden
	\end{itemize}
\end{itemize}


\subsection{Fortgeschrittene Speichertechnologien (nicht-flüchtig)}
\begin{itemize}
	\item \textbf{Ferroelectric RAM (FRAM)}
	\begin{itemize}
		\item Ferroelektrizität: Beschreibt das Phänomen, dass Stoffe mit einem elektrischen Dipolmoment durch das Anlegen eines äußeren elektrischen Feldes die Richtung der spontanen Polarisation ändern\footnote{\url{https://de.wikipedia.org/wiki/Ferroelektrikum}}
		\item Latenz beim Lesen typischerweise \(20-100ns\), hält die Daten allerdigns extrem lange (\(>10 Jahre\)); begrenze Anzahl Schreibzyklen (1012-1015)
		\item Sehr teuer (und wird auch teuer bleiben) \(\rightarrow\) wird nur für Spezialanwendungen mit langer Vorhaltezeit verwendet
	\end{itemize}
	\item \textbf{Spin Transfer Torque Memory (SPRAM)}
	\begin{itemize}
		\item Widerstand ändert sich in Abhängigkeit der Magnetorientierung
		\item Kann wie normale Schaltlogik produziert werden (weil CMOS) \(\rightarrow\) kann direkt in Chips integriert werden. Beispielsweise zwischen Funktionale Einheiten, da der Speicher nicht so heiß wird wie die Funktionalen Einheiten selbst
		\item Fertigung gut bekannt/erforscht sowie gute Leistungscharakteristik: Vmtl bald mehr als ein Bit pro Zelle möglich (multibit), wird eventuell DRAM mittelfristig ersetzen
		\item Latenz beim Lesen \(< 50ns\); unbegrenzte Anzahl Schreibzugriffe; extrem lange Haltezeit der Daten (\(>10 Jahre\))
		\item Stapelbar \(\rightarrow\) hohe Dichte/Bandbreite möglich
	\end{itemize}
	\item \textbf{Phase Change Memory (PRAM)}
	\begin{itemize}
		\item Kristalin mit unterschiedlicher Widerstand durch Erhitzung und Abkühlung; Neuschreiben durch starkes Erhitzen
		\item Byteadressierbar mit gleichem Interface/Verhalten wie Flash; kann bereits vergleichsweise günstig produziert werden \(\rightarrow\) wird Flashspeicher irgendwann ablösen
		\item Leistung: Schreibenergie vergleichbar mit Flashspeicher, Schreibgeschwindigkeit 500x schneller
		\item 100 Millitonen Schreibzyklen mit \(>300 Jahren\) Haltungszeit möglich
	\end{itemize}
\end{itemize}



\section{Appendix A: Begriffe}

\subsection{Wärmemanagement}
\begin{itemize}
	\item Maximale Leistung \(P_{max}\): Theoretischer Maximalwert, in der Praxis kaum erreicht
	\item Thermal Design Power \(P_{tdp}\): Meist etwas unterdimensioniert
	\item Aktive Leistung \(P_{active}\): Meist beschönigt bzw. unter unrealistischen Bedingungen gemessen
	\item Leerlaufleistung \(P_{idle}\): Häufig als Referenz genommen, meist realistisch. Temperatur muss beachtet werden
\end{itemize}